# this script is to generate the var_info.yml file
# import common libs
# %%
import datetime
import json
import yaml
import pandas as pd

from pathlib import Path

# %%
# load var info csv files
p_dir_csv = Path("../docs/source/related-softwares/supy/proc_var_info/")
dict_df_var_info = {}
for p_fn_csv in p_dir_csv.glob("*.csv"):
    print(p_fn_csv)
    df_var_info = pd.read_csv(p_fn_csv)
    # print(df_var_info)
    dict_df_var_info[p_fn_csv.stem] = df_var_info

# merge all dataframes
df_var_info = (
    pd.concat(
        dict_df_var_info,
        names=["use"],
        # ignore_index=True,
    )
    .reset_index()
    .set_index(["variable", "use"])
    .drop(columns="level_1")
    .rename(index=lambda x: x.replace("df_", ""))
    .reset_index("use")
)

# debugging info: show all keys with multiple values
for var in df_var_info.index.unique():
    len_var = df_var_info.loc[var].shape
    if len(len_var) > 1:
        if len_var[0] > 1:
            df_var = df_var_info.loc[var].dropna(how="all", axis=1).drop_duplicates()
            len_var = df_var.shape
            print(var, len_var[0])
            print(df_var.loc[var].apply(lambda x: x.dropna().unique()))
            print()

df_var_info.loc["DensSnow_Water"].dropna(how="all", axis=1).drop_duplicates()
# %%
# load "loading path" json file
# p_fn_json = Path("../src/supy/supy/var2siteselect.json")
# with open(p_fn_json, "r") as json_file:
#     json_data = json.load(json_file)

# load physics scheme info
p_var_phys = Path("./SUEWS_parameters_MetaData.csv")
df_var_phys = (
    pd.read_csv(p_var_phys, header=1)
    .loc[:, ["Fortrain_Alias", "physics scheme", "Options Linked To"]]
    .drop_duplicates(subset="Fortrain_Alias")
    .set_index("Fortrain_Alias")
)
df_var_phys.loc['ah_min'.lower(),'physics scheme']

# %%
# Create a dictionary with the JSON data stored under new sub-keys
yaml_data = {}
for key in df_var_info.index.unique():
    print(key)

    try:
        df_var = df_var_info.loc[key].dropna(how="all", axis=1).drop_duplicates()
        if df_var["use"][0] == "output":
            df_var = df_var.apply(lambda x: x.dropna().unique())
            # if length of unique values is 1, then reduce to a scalar
            df_var = df_var.apply(lambda x: x[0] if len(x) == 1 else x.tolist())

        print(df_var)
        dict_var = df_var.to_dict()
    except ValueError:
        dict_var = df_var_info.loc[key].dropna().to_dict()
    # replace all keys to lower case
    yaml_data[key] = {k.lower(): v for k, v in dict_var.items()}
    # if key in json_data:
    #     yaml_data[key]["loading path"] = json_data[key]

# re-organise the yaml data
# merge groups under the key 'type'
# remove the key 'group' from the sub-keys
for k, v in yaml_data.items():
    dict_var = {}
    dict_var["name"] = k
    dict_var.update(v)
    if "group" in dict_var:
        dict_var["use"] = {"output": dict_var["group"]}
        del dict_var["group"]
    else:
        dict_var["use"] = {"input": dict_var["use"]}

    # rename the key 'dimensionality' to 'dimensions':
    if "dimensionality" in dict_var:
        dims = dict_var["dimensionality"]
        if dims == "0":
            dict_var["dimensions"] = 0
        else:
            dims = dims.replace("(", "").replace(")", "").split(",")
            x_dim = {}
            dict_var["dimensions"] = {}
            remarks = dict_var["dimensionality remarks"].split("\n")
            print(dims)
            print(remarks)
            for dim, remark in zip(list(dims), remarks):
                dict_var["dimensions"][int(dim)] = remark
        # {"remarks": dict_var["dimensionality remarks"]},
        del dict_var["dimensionality"]
        del dict_var["dimensionality remarks"]

    # create a key 'unit' with value from the 'description' part
    if "unit" not in dict_var:
        # remove the unit part in square brackets
        # put the unit part in square brackets into a new key 'unit'
        dict_var["unit"] = dict_var["description"].split(" [")[-1][:-1]
        dict_var["description"] = dict_var["description"].split(" [")[0]

    # process the key 'suews-related variables'
    # rename to 'suews table headers'
    if "suews-related variables" in dict_var:
        dict_var["suews table headers"] = dict_var["suews-related variables"]
        del dict_var["suews-related variables"]

    # add a key 'usage' to setting-related variables
    if "usage" not in dict_var and "input" in dict_var["use"]:
        if "state" in dict_var["use"]["input"]:
            print(df_var_phys.loc[k.lower(),'physics scheme'])
            dict_var["usage"] = {
                df_var_phys.loc[k.lower(),'physics scheme']: df_var_phys.loc[
                    k.lower(), "Options Linked To"
                ]
            }

    # write the data back to the yaml_data
    yaml_data[k] = dict_var


# %%


# prepend comment to the top the yaml file
date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
comment = f"""
# This file is automatically generated by the script 'var_info.py'
# last updated on {date}
# Do not edit this file manually.
# To update this file, run the script 'var_info.py' again.

"""
with open("var_info_auto.yml", "w") as yaml_file:
    # Write the comment to the file
    yaml_file.write(comment)

    # Write the YAML data to a file
    yaml.dump(
        list(yaml_data.values()),
        yaml_file,
        default_flow_style=False,
        sort_keys=False,
    )
